# 基于评分的随机微分方程生成模型

两类成功的概率生成模型使用的方法是顺序地损坏带有缓慢增加噪声的训练数据，然后学习逆转这种损坏，以形成数据的生成模型。与朗之万动力学的得分匹配(SMLD)估计每个噪声尺度下的得分，然后使用朗之万动力学在生成过程中从噪声尺度递减的序列中采样。去噪扩散概率建模(Denoising Diffusion Probabilistic Modeling，DDPM)训练了一系列的概率模型来反向噪声污染的每一步，利用反向分布的函数形式的知识使训练变得容易处理。对于连续的状态空间，DDPM训练目标隐式地计算每个噪声尺度下的分数。因此，我们将这两个模型类统称为基于得分的生成模型。为了启用新的采样方法，并进一步扩展基于分数的生成模型的能力，我们提出了一个统一的框架，通过随机微分方程(SDEs)的解释来推广先前的方法。

具体来说，我们不是用有限个噪声分布来扰动数据，而是考虑一个按照扩散过程随时间演化的分布连续体。该过程将数据点逐步扩散到随机噪声中，并由一个不依赖于数据且没有可训练参数的预定SDE给出。通过反转这一过程，我们可以将随机噪声平滑地模塑成数据用于样本生成。关键的是，这个逆过程满足一个逆时间SDE，它可以从**给定边缘概率密度作为时间函数的得分的正向SDE**中推导出来。因此，我们可以通过训练一个依赖于时间的神经网络来估计分数，然后用数值方法产生样本来近似逆时SDE

![](https://cdn.jsdelivr.net/gh/keshuigu/images@main/imgs/202408160956719.png)

我们提出的框架具有若干理论和实践贡献：

- 灵活的采样和似然计算：我们可以使用任何通用的SDE求解器来集成反向时间SDE进行采样。此外，我们还提出了两种对一般SDEs不适用的特殊方法：(i)将数值SDE求解器与基于得分的MCMC(马尔可夫蒙特卡洛)方法相结合的预测-校正(PC)采样器，如郎之万MCMC和HMC；(ii)基于概率流常微分方程(ODE)的确定性采样器。前者是对现有基于评分模型的抽样方法的统一和改进。后者允许通过黑盒ODE求解器进行快速自适应采样、通过隐码进行灵活的数据操作、唯一可识别的编码以及精确似然计算。
- 可控生成：我们可以通过训练期间无法获得的信息来调节生成过程，因为条件反向时间SDE可以从无条件分数中有效地估计出来。这使得诸如类条件生成、图像修复、彩色化和其他反问题等应用都可以在不需要重新训练的情况下使用单一的无条件基于分数的模型实现。
- 统一框架：我们的框架提供了一种统一的方式来探索和调整各种SDEs，以改进基于评分的生成模型。SMLD和DDPM的方法可以合并到我们的框架中，作为两个独立的SDEs的离散化。尽管最近有报道称DDPM比SMLD具有更高的样本质量，但我们表明，在我们的框架允许的更好的架构和新的采样算法下，后者可以在CIFAR - 10上实现新的最先进的Inception分数(9.89)和FID分数(2.20)，以及从基于分数的模型中首次高保真地生成1024 x 1024图像。此外，我们在我们的框架下提出了一个新的SDE，在均匀去量化的CIFAR - 10图像上达到了2.99 bit / dim的似然值，在这个任务上设置了一个新的记录。

## 背景知识

SMLD:

![](https://cdn.jsdelivr.net/gh/keshuigu/images@main/imgs/202408190935512.png)

DDPM:

[DDPM](./Understanding_Diffusion_Models_A_Unified_Perspective.md#三种等价解释)

## SDE

对具有多个噪声尺度的数据进行扰动是以往方法成功的关键。我们提出将这一思想进一步推广到无穷多个噪声尺度，使得扰动数据分布随着噪声的增强按照SDE演化。我们的框架概述如图所示。

![](https://cdn.jsdelivr.net/gh/keshuigu/images@main/imgs/202408190937245.png)

### 用SDE对数据进行扰动

> [布朗运动，伊藤引理](https://blog.csdn.net/zk168_net/article/details/104635674)

我们的目标是构造一个以连续时间变量$t \in [0,T]$为索引的扩散过程$\{x(t)\}^T_{t=0}$，使得对于$x(0) \sim p_0$，为数据集的样本；对于$x(T) \sim p_T$，我们有易于处理的形式来有效地生成样本。即$p_0$为数据分布，$p_T$为先验分布。这个扩散过程可以建模为一个伊藤SDE的解：

$$
  dx = f(x,t)dt + g(t)dw
$$

$w$是标准Wiener过程(布朗运动)，$f(\cdot,t): \mathbb{R}^d \rightarrow \mathbb{R}^d$称为$x(t)$的漂移系数，$g(\cdot): \mathbb{R} \rightarrow \mathbb{R}$ 称为$x(t)$的扩散系数。为了便于表述，我们假设扩散系数是一个标量(而不是d x d矩阵)，且不依赖于x，但我们的理论可以推广到这些的情况。只要系数在状态和时间上都是全局Lipschitz的，则SDE有唯一的强解.我们用$p_t(x)$表示$x(t)$的概率密度，用$p_{st}(x(t) | x(s))$表示从$x(s)$到$x(t)$的转移核

通常，$p_T$是非结构化的先验分布，不包含$p_0$的信息，如固定均值和方差的高斯分布。有多种多样的方法使得SDE将数据分布扩散成固定的先验分布。我们在后面给出了由SMLD和DDPM的连续推广得到的几个例子。

### 通过反转SDE生成样本

通过从$x(T) \sim p_T$的样本开始并逆转过程，我们可以获得样本$x(0) \sim p_0$。Anderson（1982）的一个显着结果指出，扩散过程的逆过程也是一个扩散过程，在时间上向后运行，并由逆时间表给出：

$$
  dx = [f(x,t) - g(t)^2\nabla_x \log{p_t(x)}]dt + g(t)d\overline{w}
$$

其中$\overline{w}$是时间从T倒向0时的标准Wiener过程，$dt$是无限小的负时步。一旦已知所有t的每个边缘分布的得分$\nabla_x \log{p_t(x)}$，我们就可以从方程中推导出反向扩散过程，并模拟它从p0中采样。

### 优化目标

分布的分数可以通过在具有分数匹配的样本上训练基于分数的模型来估计（Hyv Ottarinen，2005; Song等人，2019年a）。为了估计$\nabla_x \log{p_t(x)}$，我们可以通过对方程的连续概括来训练时间依赖的基于分数的模型$s_\theta(x,t)$：

$$
  \theta^* = \argmin_\theta{
    \mathbb{E}_t\{
      \lambda (t) \mathbb{E}_{x(0)} \mathbb{E}_{x(t)|x(0)} [
        \lVert
          s_\theta(x(t),t) - \nabla_{x(t)} \log{p_{0t}(x(t)|x(0))}
        \rVert^2_2
      ]
    \}
  }
$$

这里，$\lambda : [0,T] \rightarrow \mathbb{R}_{>0}$是正加权函数，t在$[0,T],x(0) \sim p_0(x), x(t) \sim p_{0t}(x(t)|x(0))$上均匀采样。与SMLD和DDPM中一样，我们通常可以选择$\lambda \propto \frac{1}{\mathbb{E}[\lVert \nabla_{x(t)} \log{p_{0t}(x(t)|x(0))}\rVert^2_2]}$。请注意上式使用去噪分数匹配，但使用其他分数匹配目标，例如切片分数匹配（Song等人，2019 a）和有限差异分数匹配（Pang等人，2020年）也适用于此。

我们通常需要知道过渡内核$p_{0t}(x(t)|x(0))$来有效地求解方程。当$f(\cdot,t)$是仿射时，转移核始终是高斯分布，其中均值和方差通常以封闭形式已知，并且可以使用标准技术获得（参见Sarkka & Solin（2019）的第5.5节）。对于更一般的SDEs，我们可以求解Kolmogorov的正向方程（Error Name Thomksendal，2003）以获得$p_{0t}(x(t)|x(0))$。或者，我们可以模拟SDE以从$p_{0t}(x(t)|x(0))$进行采样并替换目标中的去噪得分匹配为切片得分匹配进行模型训练，从而绕过了$\nabla_{x(t)} \log{p_{0t}(x(t)|x(0))}$的计算。


### 从SMLD、DDPM到SDE

**SMLD**方差爆炸VE

$$
  x_i = x_{i-1} + \sqrt{\sigma^2_i - \sigma^2_i-1} z_{i-1}, \qquad i = 1, \cdots, N \\
  z_{i-1} \sim \mathcal{N}(0,I), \sigma_0 = 0
$$

$$
  N \rightarrow \infty, \qquad {\sigma_i}^N_{i=1} \rightarrow \text{a function of} \quad \sigma(t) \\
  \text{ Markov chain} \{x_i\}^N_{i=1} \rightarrow \text{连续随机过程} {x(t)}^1_{t=0} \\

  \therefore dx = \sqrt{\frac{
    d[\sigma^2(t)]
  }{
    dt
  }}dw
$$

**DDPM**方差恒定VE

$$
  x_i = \sqrt{1-\beta_i} x_{i-1} + \sqrt{\beta_i} z_{i-1} \qquad i = 1, \cdots, N \\
  \text{AS} N \rightarrow \infty, \qquad dx =  - \frac{1}{2}\beta(t)xdt + \sqrt{\beta(t)}dw
$$

更优版本

$$
dx =  - \frac{1}{2}\beta(t)xdt + \sqrt{\beta(t)(1 - e^{-2\int^t_0{\beta(s)ds}})}dw
$$

当使用相同的 $β(t)$ 并从相同的初始分布开始时，由上式引起的随机过程的方差在每个中间时间步始终受VP SDE限制。因此，我们将方程命名为： sub-VP SDE。

由于 VE、VP 和 sub-VP SDE 都具有仿射漂移系数，因此它们的扰动核$p_{0t}(x(t)|x(0))$都是高斯分布，并且可以以封闭形式计算。这使得用训练效率特别高。

## 求解反向SDE

### 通用数值 SDE 求解器

数值求解器提供来自 SDE 的近似轨迹。存在许多用于求解 SDE 的通用数值方法，例如 Euler-Maruyama 和随机 Runge-Kutta 方法（Kloeden & Platen，2013），它们对应于随机动力学的不同离散化。我们可以将它们中的任何一个应用于逆时 SDE 来生成样本。

祖先采样，即DDPM（式（4））的采样方法，实际上对应于逆时VP SDE（式（11））的一种特殊离散化（见附录E）。然而，推导新 SDE 的祖先抽样规则可能并非易事。为了解决这个问题，我们提出了反向扩散采样器（详细信息参见附录 E），它以与前向离散化相同的方式离散化反向时间 SDE，因此可以很容易地在给定前向离散化的情况下导出。如表 1 所示，在 CIFAR-10 上，对于 SMLD 和 DDPM 模型，反向扩散采样器的表现均略优于祖先采样（DDPM 型祖先采样也适用于 SMLD 模型，请参阅附录 F。）

### 预测校正采样器

与通用 SDE 不同，我们有可用于改进解决方案的附加信息。由于我们有一个基于分数的模型$s_\theta(x(t),t) \approx \log{p_{t}(x) }$，因此我们可以采用基于分数的 MCMC 方法，例如 Langevin MCMC (Parisi, 1981; Grenander & Miller, 1994) 或 HMC (Neal et al., 1994)。 ，2011）直接从 pt 采样，并修正数值 SDE 求解器的解。

具体来说，在每个时间步，数值SDE求解器首先给出下一个时间步的样本估计，扮演“预测器”的角色。然后，基于分数的MCMC方法对估计样本的边缘分布进行校正，起到“校正器”的作用。这个想法类似于 Predictor-Corrector 方法，这是一系列用于求解方程组的数值连续技术（Allgower & Georg，2012），并且我们类似地将我们的混合采样算法命名为 Predictor-Corrector (PC) 采样器。请在附录 G 中找到伪代码和完整描述。PC 采样器概括了 SMLD 和 DDPM 的原始采样方法：前者使用恒等函数作为预测器，退火 Langevin 动力学作为校正器，而后者使用祖先采样作为预测器,身份信息作为校正器。

### 概率流和与ODEs连接

基于分数的模型提供了另一种求解逆时 SDE 的数值方法。对于所有扩散过程，都存在一个相应的确定性过程，其轨迹与 SDE 具有相同的边际概率密度。一旦分数已知，就可以从 SDE 确定。我们将方程命名为概率流ODE。当得分函数由基于时间的得分模型（通常是神经网络）近似时，这是神经 ODE 的一个示例（Chen 等人，2018）。

精确似然计算 利用与神经常微分方程的连接，我们可以计算方程定义的密度。 (13) 通过变量瞬时变化公式(Chen et al., 2018)。这使我们能够计算任何输入数据的确切可能性（详细信息参见附录 D.2）。作为示例，我们在表 2 中报告了 CIFAR-10 数据集上以位/暗度为单位测量的负对数似然 (NLL)。我们计算统一反量化数据的对数似然，并且仅与以相同方式评估的模型进行比较（省略使用变分反量化（Ho et al., 2019）或离散数据评估的模型，但 DDPM (L/Lsimple) 除外，其 ELBO 值（用 * 注释）在离散数据上报告。主要结果：（i）对于 Ho 等人的相同 DDPM 模型。 (2020)，我们获得比 ELBO 更好的位/暗度，因为我们的可能性是准确的； (ii) 使用相同的架构，我们训练了另一个 DDPM 模型，其连续目标如式（1）所示。 (7)（即DDPM续），进一步提高了可能性； (iii) 对于 sub-VP SDE，与 VP SDE 相比，我们总是获得更高的可能性； (iv) 通过改进的架构（即 DDPM++ 续，第 4.4 节中的详细信息）和子 VP SDE，即使没有最大似然训练，我们也可以在统一去量化的 CIFAR-10 上设置 2.99 的新记录位/暗度。

通过整合方程来操纵潜在表示。 (13)，我们可以将任何数据点编码到潜在空间中。可以通过对反时SDE积分相应的ODE来实现解码。与其他可逆模型（例如神经常微分方程和归一化流）一样（Dinh et al., 2016；Kingma & Dhariwal, 2018），我们可以操纵这种潜在表示进行图像编辑，例如插值和温度缩放（见图 1）。 3 和附录 D.4）。

唯一可识别的编码 与大多数当前可逆模型不同，我们的编码是唯一可识别的，这意味着在足够的训练数据、模型容量和优化精度的情况下，输入的编码由数据分布唯一确定（Roeder et al., 2020）。这是因为我们的前向 SDE，方程。 (5)、没有可训练的参数，及其相关的概率流在给出完美估计分数的情况下提供相同的轨迹。我们在附录 D.5 中对此属性提供了额外的实证验证。

高效采样 与神经常微分方程一样，我们可以通过根据不同的最终条件求解方程来采样。使用固定离散化策略，我们可以生成有竞争力的样本，特别是与校正器结合使用时（表 1，“概率流采样器”，附录 D.3 中的详细信息）。使用黑盒 ODE 求解器（Dormand & Prince，1980）不仅可以产生高质量的样本（表 2，附录 D.4 中的详细信息），而且还允许我们明确地权衡精度和效率。误差容限较大，在不影响样本视觉质量的情况下，功能评估次数可减少90%以上（图3）。

## 可控的生成

我们框架的连续结构使我们不仅可以从 $p_0$ 生成数据样本，如果$ p_t(y|x(t))$是已知的,还可以从 $p_0(x(0)|y)$ | 生成数据样本

$$
  dx = \{
    f(x,t) - g(t)^2[\nabla_x \log{p_t(x)}
      + \nabla_x \log{p_t(y|x)}
    ]
    \}dt + g(t)d\overline{w}
$$

一般来说，一旦给出了前向过程的梯度估计，$\nabla_x \log{p_t(y|x(t))}$,我们可以使用基于分数的生成模型解决一大类逆问题。在某些情况下，可以训练一个单独的模型来学习前向过程$ \log{p_t(y|x(t))} $并计算其梯度。否则，我们可以利用启发式方法和领域知识来估计梯度。在附录 I.4 中，我们提供了一种广泛适用的方法来获得此类估计，而无需训练辅助模型。