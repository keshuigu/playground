# 基于评分的随机微分方程生成模型

两类成功的概率生成模型使用的方法是顺序地损坏带有缓慢增加噪声的训练数据，然后学习逆转这种损坏，以形成数据的生成模型。与朗之万动力学的得分匹配(SMLD)估计每个噪声尺度下的得分，然后使用朗之万动力学在生成过程中从噪声尺度递减的序列中采样。去噪扩散概率建模(Denoising Diffusion Probabilistic Modeling，DDPM)训练了一系列的概率模型来反向噪声污染的每一步，利用反向分布的函数形式的知识使训练变得容易处理。对于连续的状态空间，DDPM训练目标隐式地计算每个噪声尺度下的分数。因此，我们将这两个模型类统称为基于得分的生成模型。为了启用新的采样方法，并进一步扩展基于分数的生成模型的能力，我们提出了一个统一的框架，通过随机微分方程(SDEs)的解释来推广先前的方法。

具体来说，我们不是用有限个噪声分布来扰动数据，而是考虑一个按照扩散过程随时间演化的分布连续体。该过程将数据点逐步扩散到随机噪声中，并由一个不依赖于数据且没有可训练参数的预定SDE给出。通过反转这一过程，我们可以将随机噪声平滑地模塑成数据用于样本生成。关键的是，这个逆过程满足一个逆时间SDE，它可以从**给定边缘概率密度作为时间函数的得分的正向SDE**中推导出来。因此，我们可以通过训练一个依赖于时间的神经网络来估计分数，然后用数值方法产生样本来近似逆时SDE

![](https://cdn.jsdelivr.net/gh/keshuigu/images@main/imgs/202408160956719.png)

我们提出的框架具有若干理论和实践贡献：

- 灵活的采样和似然计算：我们可以使用任何通用的SDE求解器来集成反向时间SDE进行采样。此外，我们还提出了两种对一般SDEs不适用的特殊方法：(i)将数值SDE求解器与基于得分的MCMC(马尔可夫蒙特卡洛)方法相结合的预测-校正(PC)采样器，如郎之万MCMC和HMC；(ii)基于概率流常微分方程(ODE)的确定性采样器。前者是对现有基于评分模型的抽样方法的统一和改进。后者允许通过黑盒ODE求解器进行快速自适应采样、通过隐码进行灵活的数据操作、唯一可识别的编码以及精确似然计算。
- 可控生成：我们可以通过训练期间无法获得的信息来调节生成过程，因为条件反向时间SDE可以从无条件分数中有效地估计出来。这使得诸如类条件生成、图像修复、彩色化和其他反问题等应用都可以在不需要重新训练的情况下使用单一的无条件基于分数的模型实现。
- 统一框架：我们的框架提供了一种统一的方式来探索和调整各种SDEs，以改进基于评分的生成模型。SMLD和DDPM的方法可以合并到我们的框架中，作为两个独立的SDEs的离散化。尽管最近有报道称DDPM比SMLD具有更高的样本质量，但我们表明，在我们的框架允许的更好的架构和新的采样算法下，后者可以在CIFAR - 10上实现新的最先进的Inception分数(9.89)和FID分数(2.20)，以及从基于分数的模型中首次高保真地生成1024 x 1024图像。此外，我们在我们的框架下提出了一个新的SDE，在均匀去量化的CIFAR - 10图像上达到了2.99 bit / dim的似然值，在这个任务上设置了一个新的记录。

## 背景知识

SMLD:

![](https://cdn.jsdelivr.net/gh/keshuigu/images@main/imgs/202408190935512.png)

DDPM:

[DDPM](./Understanding_Diffusion_Models_A_Unified_Perspective.md#三种等价解释)

## SDE

对具有多个噪声尺度的数据进行扰动是以往方法成功的关键。我们提出将这一思想进一步推广到无穷多个噪声尺度，使得扰动数据分布随着噪声的增强按照SDE演化。我们的框架概述如图所示。

![](https://cdn.jsdelivr.net/gh/keshuigu/images@main/imgs/202408190937245.png)

### 用SDE对数据进行扰动

> [布朗运动，伊藤引理](https://blog.csdn.net/zk168_net/article/details/104635674)

我们的目标是构造一个以连续时间变量$t \in [0,T]$为索引的扩散过程$\{x(t)\}^T_{t=0}$，使得对于$x(0) \sim p_0$，为数据集的样本；对于$x(T) \sim p_T$，我们有易于处理的形式来有效地生成样本。即$p_0$为数据分布，$p_T$为先验分布。这个扩散过程可以建模为一个伊藤SDE的解：

$$
  dx = f(x,t)dt + g(t)dw
$$

$w$是标准Wiener过程(布朗运动)，$f(\cdot,t): \mathbb{R}^d \rightarrow \mathbb{R}^d$称为$x(t)$的漂移系数，$g(\cdot): \mathbb{R} \rightarrow \mathbb{R}$ 称为$x(t)$的扩散系数。为了便于表述，我们假设扩散系数是一个标量(而不是d x d矩阵)，且不依赖于x，但我们的理论可以推广到这些的情况。只要系数在状态和时间上都是全局Lipschitz的，则SDE有唯一的强解.我们用$p_t(x)$表示$x(t)$的概率密度，用$p_{st}(x(t) | x(s))$表示从$x(s)$到$x(t)$的转移核

通常，$p_T$是非结构化的先验分布，不包含$p_0$的信息，如固定均值和方差的高斯分布。有多种多样的方法使得SDE将数据分布扩散成固定的先验分布。我们在后面给出了由SMLD和DDPM的连续推广得到的几个例子。

### 通过反转SDE生成样本

通过从$x(T) \sim p_T$的样本开始并逆转过程，我们可以获得样本$x(0) \sim p_0$。Anderson（1982）的一个显着结果指出，扩散过程的逆过程也是一个扩散过程，在时间上向后运行，并由逆时间表给出：

$$
  dx = [f(x,t) - g(t)^2\nabla_x \log{p_t(x)}]dt + g(t)d\overline{w}
$$

其中$\overline{w}$是时间从T倒向0时的标准Wiener过程，$dt$是无限小的负时步。一旦已知所有t的每个边缘分布的得分$\nabla_x \log{p_t(x)}$，我们就可以从方程中推导出反向扩散过程，并模拟它从p0中采样。

### 优化目标

分布的分数可以通过在具有分数匹配的样本上训练基于分数的模型来估计（Hyv Ottarinen，2005; Song等人，2019年a）。为了估计$\nabla_x \log{p_t(x)}$，我们可以通过对方程的连续概括来训练时间依赖的基于分数的模型$s_\theta(x,t)$：

$$
  \theta^* = \argmin_\theta{
    \mathbb{E}_t\{
      \lambda (t) \mathbb{E}_{x(0)} \mathbb{E}_{x(t)|x(0)} [
        \lVert
          s_\theta(x(t),t) - \nabla_{x(t)} \log{p_{0t}(x(t)|x(0))}
        \rVert^2_2
      ]
    \}
  }
$$

这里，$\lambda : [0,T] \rightarrow \mathbb{R}_{>0}$是正加权函数，t在$[0,T],x(0) \sim p_0(x), x(t) \sim p_{0t}(x(t)|x(0))$上均匀采样。与SMLD和DDPM中一样，我们通常可以选择$\lambda \propto \frac{1}{\mathbb{E}[\lVert \nabla_{x(t)} \log{p_{0t}(x(t)|x(0))}\rVert^2_2]}$。请注意上式使用去噪分数匹配，但使用其他分数匹配目标，例如切片分数匹配（Song等人，2019 a）和有限差异分数匹配（Pang等人，2020年）也适用于此。

我们通常需要知道过渡内核$p_{0t}(x(t)|x(0))$来有效地求解方程。当$f(\cdot,t)$是仿射时，转移核始终是高斯分布，其中均值和方差通常以封闭形式已知，并且可以使用标准技术获得（参见Sarkka & Solin（2019）的第5.5节）。对于更一般的SDEs，我们可以求解Kolmogorov的正向方程（Error Name Thomksendal，2003）以获得$p_{0t}(x(t)|x(0))$。或者，我们可以模拟SDE以从$p_{0t}(x(t)|x(0))$进行采样并替换目标中的去噪得分匹配为切片得分匹配进行模型训练，从而绕过了$\nabla_{x(t)} \log{p_{0t}(x(t)|x(0))}$的计算。