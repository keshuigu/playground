## 介绍

1. 应用领域：图像生成，图像超分辨率，图像修复，图像编辑，图转图；此外，通过扩散模型学习到的隐含变量在判别性任务中有用，例如图像分割，分类和异常检测。
2. 模型的结构：基于两个阶段：（1）前向扩散阶段：通过添加高斯噪声对输入数据进行逐步扰动；（2）反向扩散阶段：生成模型的任务是通过学习逐步反向扩散过程，逐步从扩散(噪声)数据中恢复原始输入数据。
3. 包含三个子类模型：
   1. DDPMs：去噪扩散概率模型，来源于非平衡态热力学理论；DDPMs是利用潜变量估计概率分布的潜变量模型。从这个角度来看，DDPM可以看作是一种特殊的变分自动编码器，其中正向扩散阶段对应于VAE内部的编码过程，而反向扩散阶段对应于解码过程。
   2. NCSNs：噪声条件得分网络，基于得分匹配训练一个共享神经网络来估计不同噪声水平下扰动数据分布的得分函数(定义为对数密度的梯度)。
   3. SDEs：随机微分方程，代表了扩散模型的一种替代方式，通过正向和反向SDEs对扩散进行建模，可以得到有效的生成策略和强大的理论结果。SDEs可以看作是DDPMs和NCSNs的推广

## 通用框架

![](https://cdn.jsdelivr.net/gh/keshuigu/images@main/imgs/202408061440459.png)

### DDPMs

[DDPM](./DDPM.md)

### NCSNs

$p(x)$的得分函数定义为$\nabla_x \log{p ( x )}$，这些梯度给出的方向被Langevin动力学算法用于从一个随机样本$(x_0)$移动到高密度区域的样本$(x_N)$。Langevin动力学是一种受物理学启发的可用于数据采样的迭代方法。在物理学中，这种方法被用来确定一个粒子在允许粒子与其他分子相互作用的分子体系中的运动轨迹。粒子的运动轨迹受到系统的拖曳力和分子间快速相互作用产生的随机力的影响。在我们的例子中，我们可以把对数密度的梯度看作一个力，它将一个随机样本通过数据空间拖拽到高数据密度$p(x)$的区域。在物理学中，另一个术语$\omega_i$表示随机力，在我们的例子中，这个力对于逃离局部极小值是很有用的。最后，$\gamma$的值权衡了两种力的影响，因为它代表了颗粒所处环境的摩擦系数。从采样的角度来看，$\gamma$控制着更新的幅度。综上所述，Langevin动力学的迭代更新如下：

$$x_i = x_{i-1} + \frac{\gamma}{2}\nabla\log{p(x)}+\sqrt{\gamma}\cdot\omega_i,\quad i \in \{1,\cdots,N\}$$


因此，生成式模型可以采用上述方法，通过神经网络$s_θ(x)\approx \nabla_x \log{p ( x )}$估计得分后从$p ( x )$中采样。这个网络可以通过得分匹配来训练，这种方法需要优化以下目标：

$$\mathcal{L}_{sm} = \mathbb{E}_{x\sim p(x)}\lVert s_\theta(x) - \nabla_x \log{p (x)} \rVert^2_2$$

在实际中，由于$\nabla_x \log{p ( x )}$是未知的，所以不可能直接最小化这个目标。然而，也有其他方法如去噪评分匹配和切片评分匹配克服了这个问题。

实际使用中，大多数问题都与流形假设联系在一起。例如，当数据位于低维流形上时，得分估计$sθ(x)$是不一致的，这可能导致Langevin动力学从未收敛到高密度区域。在相同的工作中，作者证明了这些问题可以通过在不同尺度下对带有高斯噪声的数据进行扰动来解决。此外，他们提出通过单个噪声条件得分网络(NCSN)来学习得到的噪声分布的得分估计。
关于采样，他们采用Langevin动力学的迭代更新中的策略，并使用与每个噪声尺度相关的得分估计。

形式上的描述如下：给定一个高斯噪声尺度序列 $\sigma_1 < \sigma_2 <\cdots <\sigma_T$使得$p_{\sigma_1}(x) \approx p(x_0)$ 以及 $p_{\sigma_T}(x) \approx \mathcal{N}(0,I)$，我们可以通过去噪得分匹配使得 $s_θ(x,\sigma_t)\approx \nabla_x \log{p_{\sigma_t}(x)}, \forall t \in \{1,\cdots, T\}$，来训练一个NCSN。我们可以得到$\nabla_x\log{p_{\sigma_t}(x)}$如下：

$$\begin{split}
   p_{\sigma_t}(x_t|x)
   &= \mathcal{N}(x_t;x,\sigma_t^2\cdot I) \\
   &= \frac{1}{\sigma_t \cdot \sqrt{2\pi}} \cdot \exp{(-\frac{1}{2} \cdot (\frac{x_t - x}{\sigma_t})^2)}
\end{split}$$

从而

$$\nabla_x\log{p_{\sigma_t}(x_t|x)} = - \frac{x_t - x}{\sigma_t^2}$$

其中$x_t$是$x$的加噪版因此，对所有的$( \sigma_t )_t^{T = 1}$推广优化目标，并将梯度替换为以上形式，则得到以下优化目标：

$$\mathcal{L}_{dsm} = \frac{1}{T}\sum_{t=1}^T{\lambda(\sigma_t)
   \mathbb{E}_{p(x)}\mathbb{E}_{x_t \sim p_{\sigma_t}(x_t | x)}
   \lVert s_\theta(x) + \frac{x_t - x}{\sigma_t^2} \rVert^2_2}$$


式中：$\lambda ( \sigma_t )$为权重函数。经过训练后，神经网络将返回得分$\nabla_x\log{p_{\sigma_t}(x_t)}$的估计值，其输入为含噪图像$x_t$和对应的时间步长$t$。

### SDEs

与前两种方法类似，随机微分方程将数据分布逐步转化为噪声。然而，它是前两种方法的推广，因为在它的情况下，扩散过程被认为是连续的，从而成为随机微分方程(SDE)的解。这种扩散的逆过程可以用一个逆时间SDE来建模，它需要每个时间步的密度的得分函数。因此，生成式模型使用神经网络估计得分函数，并通过数值SDE求解器从$p(x_0)$中生成样本。与NCSNs的情况一样，神经网络接收扰动数据和时间步长作为输入，并产生对得分函数的估计。
前向扩散过程的随机微分方程有如下形式：

$$\frac{\partial x}{\partial t} = f(x, t) + \sigma(t) \cdot \omega_t
\iff \partial x = f(x,t)\partial t + \sigma (t) \partial \omega \\ (x_t)^T_{t=0}, t \in [0, T]$$

其中$ω_t$是关于t变化的高斯噪声，因此右侧第二项是$\partial \omega$，$f$是计算漂移系数的函数，$\sigma$是计算扩散系数的依赖于时间的函数。为了将扩散过程作为该SDE的解决方案，漂移系数应该被设计成使数据x0逐渐为零，而扩散系数控制添加多少高斯噪声。相关的逆时偏移定义如下：

$$\partial x  = [f(x,t) - \sigma (t)^2 \cdot \nabla_x \log p_t(x)] \cdot \partial t + \sigma(t) \cdot \partial \hat{\omega}$$

其中，$\hat{\omega}$ 表示时间反转时的布朗运动，从T到0。反向时间SDE表明，如果我们从纯噪声开始，我们可以通过移除导致数据破坏的漂移来恢复数据。移除是通过减去$\sigma (t)^2 \cdot \nabla_x \log p_t(x)$来完成的.

我们可以通过优化与NSCN中相同的目标的连续情况版本来训练神经网络$s_θ (x,t)\approx \nabla_x log p_t ( x )$，如下所示：

$$\mathcal{L}^{\star}_{dsm} = \mathbb{E}_t
[
   \lambda (t)\mathbb{E}_{p(x_0)}\mathbb{E}_{p_t(x_t | x_0)}
   \lVert
      s_\theta(x_t, t)  - \nabla_x \log{p_t (x_t | x_0)}
   \rVert^2_2
]$$
式中：$\lambda$为加权函数，$t \sim \mathcal{U}([ 0 , T ])$，服从均匀分布。我们强调，当漂移系数$f$是仿射时，$p_t ( x_t | x_0 )$是一个高斯分布。当$f$不符合这个性质时，我们不能使用去噪分数匹配，但是我们可以回退到切片分数匹配。

## 扩散模型分类

分类标准:

1. 所应用的任务
2. 所需要的输入（是否存在条件限制，什么方面的条件限制）
3. 底层框架
4. 数据集

### 无条件限制的图片生成任务

下面给出的扩散模型用于在无条件设置中生成样本。此类模型不需要监督信号，完全不受监督。图像生成的最基本和通用的设置。

#### DDPM

1. Sohl-Dickstein等形式化了扩散模型，如[DDPMs](#DDPMs)所述。所提出的网络基于具有多尺度卷积的卷积结构
2. Austin等推广到离散扩散模型，研究了前向过程中转移矩阵的不同选择。他们的结果与之前的连续扩散模型在图像生成任务上具有竞争力。
3. Ho等提出在每一步通过估计图像中的噪声来学习反向过程。（简化优化目标后的DDPM）
4. Nichol等人提出了一些改进，观察到线性噪声时间表对于低分辨率是次优的。他们表明，为了提高扩散模型在对数似然方面的性能，需要学习方差。这种变化允许更快的采样，大约需要50步
5. Song等人使用的马尔可夫前向过程替换为非马尔可夫前向过程。生成过程的变化使得模型首先预测正常样本，然后，它被用于估计链中的下一步。该变化导致采样过程更快，对质量的影响较小。结果框架被称为去噪扩散隐式模型(DDIM)。
6. Sinha等人提出了基于对比表示的扩散-解码模型(D2C)，这是一种在编码器的潜在表示上训练扩散模型的生成式方法。该框架DDPM架构，通过将潜在表示映射到图像来生成图像。
7. San - Roman等人提出了一种在推理过程中给定当前输入来估计噪声参数的方法，所需步骤较少。采用VGG-11估计噪声参数，DDPM生成图像。
8. Nachmani等人建议将扩散过程的高斯噪声分布替换为另外两个分布，即两个高斯和Gamma分布的混合。由于Gamma分布具有更高的建模能力，它们获得了更好的弗雷谢Inception Distance(FID, 衡量生成图片与原始图片的差异)值和更快的收敛速度。
9. Lam等人提出学习采样的噪声调度。与以前一样，用于训练的噪声时间表仍然是线性的。在训练得分网络后，他们假设其接近最优值，并将其用于噪声时间表训练。
10. Bond - Taylor等人提出了一个两阶段的过程，他们将矢量量化应用于图像以获得离散表示，并使用一个转换器来反向离散扩散过程，其中元素在每一步都被随机掩蔽。采样过程更快，因为扩散应用于高度压缩的表示，允许更少的去噪步骤(50 ~ 256)。
11. Watson等提出了一种寻找最优推理调度的动态规划算法，时间复杂度为O (T)，其中T为步骤数。他们在CIFAR - 10和ImageNet上使用DDPM架构进行图像生成实验。
12. Watson等人展示了如何在扩散模型的后向过程中集成重新参数化技巧，以优化一族快速采样器。他们使用核初始距离作为损失函数，展示了如何使用随机梯度下降进行优化。接下来，他们提出了一个特殊的参数化采样器家族，使用与之前相同的过程，可以用更少的采样步骤获得有竞争力的结果。
13. 与Bond - Taylor等和Watson等类似，Xiao等试图在提高采样速度的同时，也保持样本的质量、覆盖率和多样性。他们的方法是在去噪过程中集成一个GAN来区分真实样本(正向过程)和伪样本(从生成器中去噪样本)，目标是最小化软化的反向KL散度。
14. Kingma等人介绍了一类在图像密度估计上获得最先进似然的扩散模型。他们在网络的输入中加入傅里叶特征来预测噪声，并研究观察到的改进是否针对这类模型。
15. Bao等提出了一个不需要使用非马尔科夫扩散过程进行训练的推理框架。通过首先推导关于得分函数的最优均值和方差的分析估计，并使用预训练的基于得分的模型来获得评分值，它们显示出更好的结果，同时具有20到40倍的时间效率。
16. Zheng等人建议对过程进行任意步长的截断，并提出一种方法，通过放松高斯随机噪声作为前向扩散的最终输出的限制，从该分布中反演出扩散。为了避免从不可追踪的分布开始逆向过程，使用隐式生成式分布匹配扩散后的数据分布。
17. Deja等人分析了一个扩散模型的后向过程，并假设它由两个模型组成，一个生成器和一个去噪器。因此，他们提出将过程显式地分为两个部分：通过自动编码器的去噪器和通过扩散模型的生成器。
18. Wang等人通过添加噪声来增加判别器的输入数据。这在其他工作中是通过在不同的时间步长从干净图像中注入由加权扩散样本组成的高斯混合分布的噪声来实现的。噪声注入机制既适用于真实图像，也适用于虚假图像。

#### 基于评分的生成模型

1. 从先前的工作开始，Song等人提出了一些基于理论和实证分析的改进。它们涉及训练和采样两个阶段。在训练方面，作者提出了新的策略来选择噪声尺度以及如何将噪声调节纳入NCSNs。对于采样，他们提出对参数进行指数移动平均，并为Langevin动力学选择超参数，使得步长验证某个方程。Jolicoeur-Martineau等引入对抗目标和去噪得分匹配来训练基于得分的模型。此外，他们提出了一种新的采样方法，称为一致退火采样，并证明了它比退火朗之万方法更稳定。
2. Song等人改进了基于得分的扩散模型的可能性。他们通过一个新的加权函数来组合得分匹配损失来实现这一点。在文献中，作者提出了一种基于得分的生成模型，作为迭代比例拟合(IPF)的实现，该技术用于解决Schrödinger桥问题。这种新颖的方法在图像生成，以及数据集插值上进行了测试，这是可能的，因为先验可以是任何分布。
3. Vahdat等人训练了基于潜在表示的扩散模型。它们使用VAE从隐空间进行编码和解码，实现了高达56倍的采样速度。

#### SDE

1. DiffFlow是引入的一种新的生成式建模方法，它结合了规范化流和扩散概率模型。从扩散模型的角度来看，该方法有一个高达20倍的采样过程，这得益于一个可学习的前向过程，它跳过了不需要的噪声区域。
2. Jolicoeur -Martineau等介绍了一种新的SDE求解器，比Euler-Maruyama快2× ~ 5×，且不影响生成图像的质量。
3. Wang等人提出了一种新的基于Schrödinger桥的深度生成模型。这是一种两阶段的方法，其中第一阶段学习目标分布的平滑版本，第二阶段导出实际的目标。
4. Dockhorn等人通过在数据中加入另一个变量(速度)，采用了临界阻尼的郎之万扩散过程，这是过程中唯一的噪声来源。给定新的扩散空间，得到的得分函数被证明更容易学习。作者通过开发一个更合适的得分目标，称为混合得分匹配，以及一种抽样方法来扩展他们的工作，通过集成来解决SDE。
5. 为了解决由高斯噪声分布引起的高维分数模型的局限性，Deasy等人将去噪分数匹配推广到正态噪声分布。通过添加更重的尾部分布，他们的综合实验显示出有希望的结果，因为在某些情况下生成性能提高了(视分布的形状而定)。
6. Jing等人试图通过缩小扩散过程的空间来缩短扩散模型采样过程的持续时间，即扩散过程的时间步长越大，子空间越小。数据被投影到一组有限的子空间中，在特定的时间，每个子空间都与一个得分模型相关联。这在降低计算成本的同时，提高了性能
7. Kim等人提出将扩散过程转化为非线性过程。这是通过使用可训练的归一化流模型来实现的，该模型在潜在空间中对图像进行编码，现在可以将其线性扩散到噪声分布中。然后将类似的逻辑应用到去噪过程中。
8. Ma等人的目标是使后向扩散过程更加省时，同时保持合成性能。在基于得分的扩散模型家族中，他们开始在频域分析反向扩散，随后将空频滤波器应用到采样过程中，其目的是将关于目标分布的信息集成到初始噪声采样中。

### 有条件图像生成

条件通常基于各种源信号，在大多数情况下使用一些类标签。一些方法同时执行无条件生成和条件生成


Pandey等构建了一个生成器-精炼器框架，其中生成器为VAE，精炼器为受VAE输出约束的DDPM。由于DDPM只增加了细节信息，因此可以利用VAE的潜在空间来控制生成图像的内容。训练框架后，生成的DDPM能够泛化到不同的噪声类型。

Ho等人提出了级联扩散模型(Cascaded Diffusion Models，CDM)，它是一种基于ImageNet类生成高分辨率图像的方法。该框架使用多个扩散模型，其中来自管道的第一个模型生成以图像类为条件的低分辨率图像。随后的模型负责生成越来越高分辨率的图像，同时受类和低分辨率图像的条件限制。

Liu等人研究了基于扩散和基于能量的模型的相似功能，并利用后者模型的组成结构，提出将多个扩散模型组合起来用于条件图像合成。在逆过程中，多个扩散模型的组合，每个模型与不同的条件相关联，可以通过合取或否定来实现。

Ho等人介绍了一种不需要分类器的引导方法。它只需要一个条件扩散模型和一个无条件扩散模型。但是使用相同的模型来学习这两种情况。无条件模型以类标识符等于0进行训练。


### 图转图

Saharia等人提出了一个用于图像到图像转换的扩散模型，主要关注四个任务：彩色化、修复、去剪切和JPEG恢复。值得注意的是，所提出的框架在所有四个任务中都是相同的，这意味着它不会对每个任务进行定制修改。


Li等人介绍了一种基于布朗桥的图像到图像翻译的扩散模型，以及GANs。提出的过程开始于使用VQ - GAN对图像进行编码。在量化后的隐空间中，扩散过程以布朗桥的形式映射在源域和目标域的隐表示之间。最后，另一个VQ - GAN对量化后的向量进行解码，以便在新的域中合成图像。Wolleb等延续了他们在文献中提出的工作，通过将分类器替换为针对任务的另一个模型来扩展他们的扩散模型。因此，在采样过程的每一步，任务特定网络的梯度被注入。


### 文本生成图像

文献引入Imagen作为文本生成图像的一种方法。它由一个用于文本序列的编码器和用于生成高分辨率图像的级联扩散模型组成。这些模型也是以编码器返回的文本嵌入为条件的。此外，作者引入了一组新的字幕(拉丝机)用于文本到图像的评估。Gu等人提出了VQ - Diffusion模型，这是一种文本到图像合成的方法，它不存在以往方法的单向偏差。利用其掩盖机制，所提出的方法避免了推断过程中错误的积累。该模型分为两个阶段，第一阶段基于VQ - VAE，通过离散的令牌学习表示图像，第二阶段是在VQ - VAE的离散潜在空间上运行的离散扩散模型。Avrahami等人提出了一个基于CLIP图像和文本嵌入的文本条件扩散模型。这是一个两阶段的方法，其中第一阶段生成图像嵌入，第二阶段(解码器)生成以图像嵌入和文本描述为条件的最终图像。


TODO CLIP

龙巴赫等人介绍了一种使用相同过程来创建艺术形象的修改：从数据库中提取图像的CLIP潜在空间中的k近邻，然后通过这些嵌入引导反向去噪过程来生成新的图像。由于CLIP的潜在空间是由文本和图像共享的，因此扩散也可以由文本提示来引导。Jiang等人提出了一个框架来生成具有丰富服装表示的全身人体图像，给定三个输入：一个人体姿势，一个服装形状的文本描述和另一个服装纹理的文本。该方法将前一个文本提示编码为一个嵌入向量，并将其输入到一个自动编码器中，生成形式映射图。接下来，一个基于扩散的转换器从多个多级码本(每个具体到一个纹理)中采样后一个文本提示的嵌入表示，这是VQ - VAE中提出的一种机制。


### 超分辨率

Saharia等将扩散模型应用于超分辨率。他们的逆过程学习在低分辨率版本的条件下生成高质量的图像。Daniels等人使用基于得分的模型从两个分布的Sinkhorn耦合中采样。他们的方法是用神经网络对双变量进行建模，然后求解最优运输问题。在对神经网络进行训练后，可以通过Langevin动力学和基于得分的模型进行采样。

TODO 最优运输问题

### 图片编辑

Meng等人在各种引导图像生成任务中使用扩散模型，例如基于笔画的编辑和图像合成。通过求解反向SDE，用一个通用的扩散模型来合成图像，而不需要任何自定义的数据集或用于训练的修改。文献介绍了第一种基于自然语言描述编辑图像特定区域的方法。待修改的区域由用户通过掩码输入。该方法依靠CLIP指导，根据文本输入生成图像。在每个去噪步骤之后，将掩膜应用在潜在图像上，同时也添加原始图像的噪声版本。
Avrahami等人将潜在扩散模型应用于局部编辑图像，使用文本。VAE将图像和自适应时间掩模(要编辑的区域)编码到发生扩散过程的潜在空间中。

## 未来方向

局限性。扩散模型最显著的缺点仍然是需要在推断时执行多个步骤，以仅生成一个样本。尽管在这个方向上进行了大量的研究，GANs在生成图像方面仍然速度较快。扩散模型的其他问题可以与文本生成高清图像使用CLIP嵌入的常用策略联系起来。例如，Ramesh等人强调他们的模型努力在图像中生成可读的文本，并通过声明CLIP嵌入不包含拼写的信息来激励行为。因此，当使用这样的嵌入来调节去噪过程时，模型可以继承这类问题。

未来方向。为了降低不确定性水平，扩散模型一般避免在采样过程中采取较大的步骤。事实上，采取较小的步骤可以确保每一步生成的数据样本都是由学习到的高斯分布解释的。在应用梯度下降优化神经网络时也观察到类似的行为。事实上，在梯度的负方向上迈出较大的一步，即使用非常大的学习率，可以导致将模型更新到具有高度不确定性的区域，而对损失值没有控制。在未来的工作中，将从高效的优化器中借用的更新规则转移到扩散模型中，可能会导致更有效的采样(生成)过程。除了当前研究更有效的扩散模型的趋势外，未来的工作可以研究扩散模型在其他计算机视觉任务中的应用，例如图像去雾、视频异常检测或视觉问答。即使我们发现了一些在医学图像中研究异常检测的工作，这个任务也可以在其他领域进行探索，例如视频监控或工业检测。

一个有趣的研究方向是评估扩散模型在判别性任务中学习到的表示空间的质量和效用。这至少可以通过两种截然不同的方式来实现。以一种直接的方式，通过在去噪模型提供的潜在表示的基础上学习一些判别模型，以解决一些分类或回归任务。以一种间接的方式，通过扩散模型生成的真实样本来增加训练集。

在未来，对扩散模型的研究还可以扩展到学习一次性解决多个任务的多用途模型。创建一个扩散模型来生成多种类型的输出，同时受限于各种类型的数据，例如文本、类标签或图像，可能会使我们更接近于理解开发通用人工智能(AGI)的必要步骤。